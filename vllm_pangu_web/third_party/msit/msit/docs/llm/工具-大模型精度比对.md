# 大模型精度比对



## 1 简介

- 本节主要介绍通过命令行的方式进行精度数据比对，执行精度比对操作前需要先完成 CPU 或 GPU 与 NPU 的精度数据 dump，参见 [PyTorch 场景下的数据采集](./工具-Pytorch场景数据dump.md)章节和[ATB 场景下的数据采集](./工具-DUMP加速库数据使用说明.md)。

- 精度比对支持的数据来源

|    数据一   |     数据二 | 是否支持比对 |
| ---------- | ---------- | ---------- |
|     atb    |   PyTorch  |    是      |
|    PyTorch |   PyTorch  |    是      |
|     atb    |   atb      |    是      |

- 工具使用子命令 msit llm compare 进行比对，提供有精度问题的数据与标杆数据之间的比对能力。可支持单卡和多卡场景的精度数据比对。
- 由于标杆数据和待比较数据的 dtype 可能不一致，为方便比较会将其全部都转换为 fp32 进行比较，开启 debug 级别的日志信息会看到打屏信息。

**使用场景**  

- 同一结构模型，在不同硬件环境或配置条件下的精度差异，例如ATB与PyTorch模型精度差异、不同参数配置下的ATB或PyTorch模型精度差异和NPU、GPU、CPU硬件环境运行的模型精度差异。

**注意事项**

- NPU 自研 API，在 CPU 或 GPU 侧若没有对应的算子（模块/层），该处 的 dump 数据不比对。
- 不支持连续推理多个prompt的数据dump。
- 不支持Moe模型的精度比对。
- 不支持多机场景的数据采集。


**比对匹配条件**

进行精度比对时，需要判断 atb 的算子（模块/层）与 PyTorch 的算子（模块/层）是否可以比对，须满足以下匹配条件：

- 两个算子（模块/层）的名称对应，如 PyTorch 场景下大模型中的 self-attention算子 的命名规则为 root.model.layer1.self_attn，ATB 场景中的 self-attention算子 命名规则为 1_Attention。
- 两个算子（模块/层）的名称不对应，但分析两边组图，两个算子或模块实现相同功能且输入输出一致。

通常满足以上两个条件，工具就认为是同一个算子（模块/层），对其进行匹配，后续进行相应的计算。


## 2 精度比对操作指导

### 2.1 命令行方式

```shell
msit llm compare -gp {path} -mp {path}  [可选参数] 
```

## 参数完整说明

| 参数名                 | 描述                                                         | 是否必选 |
| ---------------------- | ------------------------------------------------------------ | -------- |
| -gp, --golden-path     | 标杆数据路径，支持单个数据文件路径或文件夹                   | 是       |
| -mp, --my-path         | 待比较的数据路径，支持单个数据文件路径或文件夹                   | 是     |
| -w, --weight           | 针对大模型反量化后权重和浮点权重的比较                          | 否       |
| -mf, --op-mapping-file | 算子类型映射关系文件路径，加速库模型与torch模型比对场景下按需提供，针对用户自定义的映射关系 | 否       |
| -l, --log-level        | 日志级别，默认为info，可选值有：debug, info, warning, error, fatal, critical | 否       |
| -o, --output           | 比对结果csv的输出路径，如果不指定则默认为当前目录下                                        | 否       |
| -cl, --cmp-level       | 比对层级，默认对layer、module、api级别全部比对, 可选值有：layer, module, api， logits，如进行logits比对则必须指定该参数                 | 否     |
| -st, --stats           | dump统计量比对，指定是否进行统计量比对并输出结果，默认关闭，如果要对统计量进行比对，则需要提供dump下的统计量数据（dump统计量参考 [DUMP统计量说明](/msit/docs/llm/工具-DUMP加速库数据使用说明.md)）                  | 否     |
| -alg, --custom-algorithms   | 指定自定义比对算法，格式应为“python_file_path.py:function”。自定义算法最好为独立文件，方法示例："def foo(golden_tensor, my_tensor): return float_value, string_message"，使用方式：-alg python_file_path.py:foo python_file_path.py:foo2| 否       |
| -r, --rank   | 指定rank进行数据比对。默认比对所有rank数据。仅支持[TorchAir场景](../llm/TorchAir场景-整网算子精度比对.md)| 否       |
| -h, --help   | 命令行参数帮助信息| 否       |


### 2.1.2 整网比对场景

#### PyTorch 场景和 ATB 场景比对

整网比对场景包括 CPU 或 GPU 与 NPU 环境落盘的整网数据比对，会落盘大模型中所有 layer、module 和算子的输入输出数据，支持单卡和多卡，可同时比对多卡的 dump 数据。多机场景需要每个设备单独执行比对操作。

1. 参见 [PyTorch 场景下的数据采集](./工具-Pytorch场景数据dump.md)章节和[ATB 场景下的数据采集](./工具-DUMP加速库数据使用说明.md)完成 CPU 或 GPU 与 NPU 的精度数据 dump。

模型脚本示例（llama2-7b）：

```python
from msit_llm import DumpConfig, register_hook # 在文件开头导入 DumpConfig 和 register_hook 接口
from transformers import AutoTokenizer, LlamaForCausalLM

# 需自行保证模型配置代码文件安全可靠。在确保其安全性的前提下，可以使用以下代码。否则，请将'trust_remote_code'置为False
tokenizer = AutoTokenizer.from_pretrained("/home/data/Llama-2-7b-hf", trust_remote_code=True)

# 需自行保证模型配置代码文件安全可靠。在确保其安全性的前提下，可以使用以下代码。否则，请将'trust_remote_code'置为False
model = LlamaForCausalLM.from_pretrained("/home/data/Llama-2-7b-hf", trust_remote_code=True).to('npu') # 初始化模型实例model

# dump相关代码，在模型初始化后添加
dump_config = DumpConfig(dump_path="./", seed=2345, token_range=[0,1,2,3,4])
register_hook(model, dump_config)

# 执行推理脚本
with torch.no_grad():
    inputs = tokenizer(
                "What's deep learning?",
                return_tensors="pt", 
                truncation=True, 
                max_length=10).to('npu')
    
    # delete token_type_ids
    if 'token_type_ids' in inputs:
        del inputs['token_type_ids']

    outputs = model.generate(**inputs, do_sample=False, max_new_tokens=10)
```

2. 运行命令：

   ```shell
   msit llm compare -gp {path} -mp {path}  -o {save_path}
   ```

- 完成比对后会生成一个 `msit_cmp_report_{TIMESTAMP}.xlsx`，保存按layer、module、api比对的最终结果。默认文件保存路径在当前目录下，如果使用`--output/-o`指定目录，保存路径则为指定的`{OUTPUT_DIR}`。

#### 比对文件关系

###### 文件夹内容

| PyTorch模型 | 内容             | ATB模型 |
| ------------| -----------------| -------- |
| 0 文件夹    |  prefill数据      | prefill数据 + 第一次decoder数据 |
| 1 文件夹    |  第一次decoder数据 |  第二次decoder数据 |
| 2 文件夹    |  第二次decoder数据 |  第三次decoder数据 |
| 3 文件夹    |  第三次decoder数据 | 第四次decoder 数据  |
···
| n-1 文件夹  |   第n-1次decoder数据 |  第n次decoder数据  |
| n 文件夹    |   第n次decoder数据 |  无数据  |

###### 文件夹比对关系

| PyTorch模型的文件夹id |  ATB模型的文件夹id |
| --------------| ------------|
| 0             |  0          |
| 1             |  0          |
| 2             |  1          |
| 3             |  2          |
···
| n-1           |   n-2       |
| n             |   n-1       |

- 由于 ATB 模型实现原因，在 dump 数据后，id 为 0 的文件夹会同时保存 prefill 和 decoder 的数据，因此在进行比对时，需要将文件夹的 id 进行错位比较。


3. 查看比对结果，请参见 [精度比对结果参数说明](./精度比对结果参数说明.md)。


#### PyTorch 场景和 PyTorch 场景比对

Torch场景下的整网精度比对根据数据采集的设备不同，包含以下四种场景：
|选取的标杆数据dump设备 |  待比对精度的数据dump设备 |
| --------------| ------------|
| CPU             |  CPU          |
| CPU             |  GPU          |
| GPU             |  CPU          |
| GPU             |  GPU          |

支持单卡和多卡，可同时比对多卡的 dump 数据。

1. 参见 [PyTorch 场景下的数据采集](./工具-Pytorch场景数据dump.md)章节完成 CPU 或 GPU 的精度数据 dump。

2. 运行命令：

   ```shell
   msit llm compare -gp {path} -mp {path} -o {save_path}
   ```

3. 查看比对结果，请参见 [精度比对结果参数说明](./精度比对结果参数说明.md)。


#### ATB 场景和 ATB 场景比对

整网比对场景是包含：NPU 与 NPU 环境落盘的整网数据比对。

支持单卡和多卡，可同时比对多卡的 dump 数据。

1. 参见 [ATB 场景下的数据采集](./工具-DUMP加速库数据使用说明.md)章节完成 CPU 或 GPU 的精度数据 dump。

2. 运行命令：

   ```shell
   msit llm compare -gp {path} -mp {path}  -o {save_path}
   ```

3. 查看比对结果，请参见 [精度比对结果参数说明](./精度比对结果参数说明.md)。

 
 ### 2.1.3 logits 比对场景

logits 比对场景：出现精度问题后定位第一个出现精度问题的 token。

可参考 [加速库场景-输出Token的logits精度比对](./加速库场景-输出Token的logits精度比对.md) 章节。